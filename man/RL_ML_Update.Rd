% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ReinforcementLearningFunctions.R
\name{RL_ML_Update}
\alias{RL_ML_Update}
\title{RL_ML_Update}
\usage{
RL_ML_Update(ExperimentGrid = ExperimentGrid, ModelRun = counter,
  NewPerformance = NewPerformance, BestPerformance = BestPerformance,
  TrialVector = Trials, SuccessVector = Successes, GridIDS = GridIDs,
  BanditArmsCount = BanditArmsN,
  RunsWithoutNewWinner = RunsWithoutNewWinner,
  MaxRunsWithoutNewWinner = MaxRunsWithoutNewWinner,
  MaxNumberModels = MaxNumberModels, MaxRunMinutes = MaxRunMinutes,
  TotalRunTime = TotalRunTime, BanditProbabilities = BanditProbs)
}
\arguments{
\item{ExperimentGrid}{This is a data.table of grid params and model results}

\item{ModelRun}{Model iteration number}

\item{TrialVector}{Numeric vector with the total trials for each arm}

\item{SuccessVector}{Numeric vector with the total successes for each arm}

\item{GridIDS}{The numeric vector that identifies which grid is which}

\item{BanditArmsCount}{The number of arms in the bandit}

\item{RunsWithoutNewWinner}{Counter of the number of models previously built without being a new winner}

\item{MaxRunsWithoutNewWinner}{Maximum number of models built without a new best model (constraint)}

\item{MaxNumberModels}{Maximum number of models to build (constraint)}

\item{MaxRunMinutes}{Run time constraint}

\item{TotalRunTime}{Cumulative run time in minutes}

\item{BanditProbabilities}{Inital probabilities from RL_Initialize()}

\item{NEWGrid}{Previous grid passed in}
}
\description{
RL_ML_Update updates the bandit probabilities for selecting different grids
}
\examples{
RL_Update_Output <- RL_ML_Update(
  ExperimentGrid = ExperimentGrid,
  ModelRun = run,
  NEWGrid = NewGrid,
  TrialVector = Trials,
  SuccessVector = Successes,
  GridIDS = GridIDs,
  BanditArmsCount = BanditArmsN,
  RunsWithoutNewWinner = RunsWithoutNewWinner,
  MaxRunsWithoutNewWinner = MaxRunsWithoutNewWinner,
  MaxNumberModels = MaxNumberModels,
  MaxRunMinutes = MaxRunMinutes,
  TotalRunTime = TotalRunTime,
  BanditProbabilities = BanditProbs)
BanditProbs <- RL_Update_Output[["BanditProbs"]]
Trials <- RL_Update_Output[["Trials"]]
Successes <- RL_Update_Output[["Successes"]]
NewGrid <- RL_Update_Output[["NewGrid"]]
}
\seealso{
Other Reinforcement Learning: \code{\link{RL_Initialize}},
  \code{\link{RL_Update}}
}
\author{
Adrian Antico
}
\concept{Reinforcement Learning}
