% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ReinforcementLearningFunctions.R
\name{RPM_Binomial_Bandit}
\alias{RPM_Binomial_Bandit}
\title{RPM_Binomial_Bandit}
\usage{
RPM_Binomial_Bandit(
  Success,
  Trials,
  Alpha = 1L,
  Beta = 1L,
  SubDivisions = 1000L
)
}
\arguments{
\item{Success}{Vector of successes. One slot per arm.}

\item{Trials}{Vector of trials. One slot per arm.}

\item{Alpha}{Prior parameter for success}

\item{Beta}{Prior parameter for trials}

\item{SubDivisions}{Default is 100L in the stats package. Changed it to 1000 for this function.}
}
\value{
Probability of each arm being the best arm compared to all other arms.
}
\description{
RPM_Binomial_Bandit computes randomized probability matching probabilities for each arm being best in a multi-armed bandit. Close cousin to Thomson Sampling.
}
\seealso{
Other Reinforcement Learning: 
\code{\link{RL_Initialize}()},
\code{\link{RL_ML_Update}()},
\code{\link{RL_Update}()}
}
\author{
Adrian Antico
}
\concept{Reinforcement Learning}
