% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AutomatedTimeSeriesModels.R
\name{AutoBanditSarima}
\alias{AutoBanditSarima}
\title{AutoBanditSarima}
\usage{
AutoBanditSarima(data, TargetVariableName, DateColumnName,
  TimeAggLevel = "week", EvaluationMetric = "MAE",
  NumHoldOutPeriods = 5L, NumFCPeriods = 5L, MaxLags = 5L,
  MaxSeasonalLags = 0L, MaxMovingAverages = 5L,
  MaxSeasonalMovingAverages = 0L, MaxFourierPairs = 2L,
  TrainWeighting = 0.5, MaxConsecutiveFails = 25L,
  MaxNumberModels = 100L, MaxRunTimeMinutes = 10L)
}
\arguments{
\item{data}{Source data.table}

\item{TargetVariableName}{Name of your time series target variable}

\item{DateColumnName}{Name of your date column}

\item{TimeAggLevel}{Choose from "year", "quarter", "month", "week", "day", "hour"}

\item{EvaluationMetric}{Choose from MAE, MSE, and MAPE}

\item{NumHoldOutPeriods}{Number of time periods to use in the out of sample testing}

\item{NumFCPeriods}{Number of periods to forecast}

\item{MaxLags}{A single value of the max number of lags to test}

\item{MaxSeasonalLags}{A single value of the max number of seasonal lags to test}

\item{MaxMovingAverages}{A single value of the max number of moving averages to test}

\item{MaxSeasonalMovingAverages}{A single value of the max number of seasonal moving averages to test}

\item{MaxFourierPairs}{A single value of the max number of fourier pairs to test}

\item{TrainWeighting}{Model ranking is based on a weighted average of training metrics and out of sample metrics. Supply the weight of the training metrics, such as 0.50 for 50 percent.}

\item{MaxConsecutiveFails}{When a new best model is found MaxConsecutiveFails resets to zero. Indicated the number of model attemps without a new winner before terminating the procedure.}

\item{MaxNumberModels}{Indicate the maximum number of models to test.}

\item{MaxRunTimeMinutes}{Indicate the maximum number of minutes to wait for a result.}
}
\value{
1. DataSetName - ModelFrequency means that I used forecast::findfrequency() to define the periodicity of the time series data (versus user-supplied)

2. BoxCox - "skip" means I didn't use it

3. IncludeDrift - TRUE or FALSE in forecast::Arima() 

4. SeasonalDifferences - 0, 1, 2, ... Set to 0 by default as values > 0 can cause model runs to take significantly longer depending on the size of the data

5. SeasonalMovingAverages - Q in Arima(p,d,q)(P,D,Q)

6. SeasonalLags - P in Arima(p,d,q)(P,D,Q)

7. MaxFourierTerms - used in xreg argument in Arima

8. Differences - d in Arima(p,d,q)(P,D,Q)

9. MovingAverages - q in Arima(p,d,q)(P,D,Q)

10. Lags - p in Arima(p,d,q)(P,D,Q)

11. BiasAdj - TRUE if BoxCox isn't "skip"

12. GridName - ID for set of function arguments that are treated like hyperparameters

13. Train_MSE - MSE of the training data fit

14. Train_MAE - MAE of the training data fit

15. Train_MAPE - MAPE of the training data fit

16. Validate_MSE - MSE of the validation data fit

17. Validate_MAE - MAE of the validation data fit

18. Validate_MAPE - MAPE of the validation data fit

19. Blended_MSE - MSE  weighted by the TrainWeighting argument so that the Blended MSE = TrainWeighting * Train_MSE + (1 - TrainWeighting)  * Validate_MSE

20. Blended_MAE - like above

21. Blended_MAPE - like above

# Non overlapping set of Arima arguments in order of increasing sophistication

22. BanditProbs_StratifyParsimonousGrid_3 

23. BanditProbs_StratifyParsimonousGrid_4 

24. BanditProbs_StratifyParsimonousGrid_5 

25. BanditProbs_StratifyParsimonousGrid_6 

26. BanditProbs_StratifyParsimonousGrid_7 

27. BanditProbs_StratifyParsimonousGrid_8 

28. BanditProbs_StratifyParsimonousGrid_9 

29. BanditProbs_StratifyParsimonousGrid_10 

30. RunTime - Time taken to build the model using the set of arguments

31. ModelRankByDataType - There are 4 data types: user-supplied frequency or not (2) and forecast::tsclean() or not (2)

32. ModelRank - the rank of the model based on the Blended_xxx measure

34. ModelRunNumber - The order that the model was run
}
\description{
AutoBanditSarima is a multi-armed bandit model testing framework for SARIMA. Randomized probability matching is the underlying bandit algorithm. Model evaluation is done by blending the training error and the validation error from testing the model on out of sample data. The bandit algorithm compares the performance of the current build against the previous builds which starts with the classic auto.arima from the forecast package. Depending on how many lags, moving averages, seasonal lags and moving averages you test the number of combinations of features to test begins to approach 100,000 different combinations of settings. The function tests out transformations, differencing, and variations of the lags and moving averages. The paramter space is broken up into various buckets that are increasing in sophistication. The bandit algorithm samples from those buckets and based on many rounds of testing it determines which buckets to generate samples from more frequently based on the models performance coming from that bucket. All of the models have performance data collected on them and a final rebuild is initiated when a winner is found. The rebuild process begins by retraining the model with the settings that produced the best performance. If the model fails to build, for whatever reason, the next best buildable model is rebuilt.
}
\examples{
\donttest{
# Pull in data
data <- data.table::as.data.table(fpp::cafe)
data.table::setnames(data, "x", "Weekly_Sales")
data.table::set(data, j = "Date", value = "1982-01-01")
data.table::setcolorder(data, c(2,1))
data[, Date := as.POSIXct(Date)]

# "1min"
data[, xx := 1:.N][, Date := Date + lubridate::minutes(1 * xx)][, xx := NULL]

# "5min"
#data[, xx := 1:.N][, Date := Date + lubridate::minutes(5 * xx)][, xx := NULL]

# "10min"
#data[, xx := 1:.N][, Date := Date + lubridate::minutes(10 * xx)][, xx := NULL]

# "15min"
#data[, xx := 1:.N][, Date := Date + lubridate::minutes(15 * xx)][, xx := NULL]

# "30min"
#data[, xx := 1:.N][, Date := Date + lubridate::minutes(30 * xx)][, xx := NULL]

# "hour"
#data[, xx := 1:.N][, Date := Date + lubridate::hours(xx)][, xx := NULL]

# Build model
Output <- RemixAutoML::AutoBanditSarima(
  data = data,
  TargetVariableName = "Weekly_Sales",
  DateColumnName = "Date",
  TimeAggLevel = "1min",
  EvaluationMetric = "MAE",
  NumHoldOutPeriods = 5L,
  NumFCPeriods = 5L,
  MaxLags = 5L,
  MaxSeasonalLags = 0L,
  MaxMovingAverages = 5L, 
  MaxSeasonalMovingAverages = 0L,
  MaxFourierPairs = 2L,
  TrainWeighting = 0.50,
  MaxConsecutiveFails = 50L,
 MaxNumberModels = 500L,
 MaxRunTimeMinutes = 30L)

# View output
Output$Forecast[ModelRank == min(ModelRank)]
View(Output$PerformanceGrid[DataSetName == "TSCleanModelFrequency"])
}
}
\seealso{
Other Time Series: \code{\link{AutoBanditNNet}},
  \code{\link{AutoTBATS}},
  \code{\link{CarmaHoldoutMetrics}},
  \code{\link{DifferenceDataReverse}},
  \code{\link{DifferenceData}},
  \code{\link{FinalBuildArfima}},
  \code{\link{FinalBuildArima}},
  \code{\link{FinalBuildETS}},
  \code{\link{FinalBuildNNET}},
  \code{\link{FinalBuildTBATS}},
  \code{\link{FinalBuildTSLM}},
  \code{\link{GenerateParameterGrids}},
  \code{\link{OptimizeArfima}},
  \code{\link{OptimizeArima}}, \code{\link{OptimizeETS}},
  \code{\link{OptimizeNNET}}, \code{\link{OptimizeTBATS}},
  \code{\link{OptimizeTSLM}},
  \code{\link{ParallelAutoARIMA}},
  \code{\link{ParallelAutoArfima}},
  \code{\link{ParallelAutoETS}},
  \code{\link{ParallelAutoNNET}},
  \code{\link{ParallelAutoTBATS}},
  \code{\link{ParallelAutoTSLM}},
  \code{\link{RL_Performance}},
  \code{\link{Regular_Performance}},
  \code{\link{StackedTimeSeriesEnsembleForecast}},
  \code{\link{TimeSeriesDataPrepare}},
  \code{\link{WideTimeSeriesEnsembleForecast}}
}
\author{
Adrian Antico
}
\concept{Time Series}
