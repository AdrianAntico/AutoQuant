% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AutoCatBoostHurdleModel.R
\name{AutoCatBoostHurdleModel}
\alias{AutoCatBoostHurdleModel}
\title{AutoCatBoostHurdleModel}
\usage{
AutoCatBoostHurdleModel(
  data = NULL,
  TrainOnFull = FALSE,
  ValidationData = NULL,
  TestData = NULL,
  Buckets = 0L,
  TargetColumnName = NULL,
  FeatureColNames = NULL,
  PrimaryDateColumn = NULL,
  WeightsColumnName = NULL,
  IDcols = NULL,
  EncodingMethod = list(classifier = "credibility", regression = "credibility"),
  TransformNumericColumns = NULL,
  Methods = c("Asinh", "Asin", "Log", "LogPlus1", "Sqrt", "Logit"),
  ClassWeights = NULL,
  SplitRatios = c(0.7, 0.2, 0.1),
  task_type = "GPU",
  ModelID = "ModelTest",
  Paths = NULL,
  DebugMode = FALSE,
  MetaDataPaths = NULL,
  SaveModelObjects = FALSE,
  ReturnModelObjects = TRUE,
  NumOfParDepPlots = 10L,
  PassInGrid = NULL,
  GridTune = FALSE,
  BaselineComparison = "default",
  MaxModelsInGrid = 1L,
  MaxRunsWithoutNewWinner = 20L,
  MaxRunMinutes = 60L * 60L,
  MetricPeriods = 25L,
  Langevin = FALSE,
  DiffusionTemperature = 10000,
  Trees = list(classifier = 500, regression = 500),
  Depth = list(classifier = 8, regression = 8),
  RandomStrength = list(classifier = 1, regression = 1),
  BorderCount = list(classifier = 254, regression = 254),
  LearningRate = list(classifier = NULL, regression = NULL),
  L2_Leaf_Reg = list(classifier = NULL, regression = NULL),
  RSM = list(classifier = 1, regression = 1),
  BootStrapType = list(classifier = "Bayesian", regression = "Bayesian"),
  GrowPolicy = list(classifier = "SymmetricTree", regression = "SymmetricTree")
)
}
\arguments{
\item{data}{Source training data. Do not include a column that has the class labels for the buckets as they are created internally.}

\item{TrainOnFull}{Set to TRUE to use all data}

\item{ValidationData}{Source validation data. Do not include a column that has the class labels for the buckets as they are created internally.}

\item{TestData}{Souce test data. Do not include a column that has the class labels for the buckets as they are created internally.}

\item{Buckets}{A numeric vector of the buckets used for subsetting the data. NOTE: the final Bucket value will first create a subset of data that is less than the value and a second one thereafter for data greater than the bucket value.}

\item{TargetColumnName}{Supply the column name or number for the target variable}

\item{FeatureColNames}{Supply the column names or number of the features (not included the PrimaryDateColumn)}

\item{PrimaryDateColumn}{Supply a date column if the data is functionally related to it}

\item{WeightsColumnName}{Column name for weights variable}

\item{IDcols}{Includes PrimaryDateColumn and any other columns you want returned in the validation data with predictions}

\item{EncodingMethod}{'binary', 'm_estimator', 'credibility', 'woe', 'target_encoding', 'poly_encode', 'backward_difference', 'helmert'}

\item{TransformNumericColumns}{Transform numeric column inside the AutoCatBoostRegression() function}

\item{Methods}{Choose transformation methods}

\item{ClassWeights}{Utilize these for the classifier model}

\item{SplitRatios}{Supply vector of partition ratios. For example, c(0.70,0.20,0,10).}

\item{task_type}{Set to 'GPU' or 'CPU'}

\item{ModelID}{Define a character name for your models}

\item{Paths}{The path to your folder where you want your model information saved}

\item{DebugMode}{Print steps to screen by setting to TRUE}

\item{MetaDataPaths}{TA character string of your path file to where you want your model evaluation output saved. If left NULL, all output will be saved to Paths.}

\item{SaveModelObjects}{Set to TRUE to save the model objects to file in the folders listed in Paths}

\item{ReturnModelObjects}{TRUE to return the models}

\item{NumOfParDepPlots}{Set to pull back N number of partial dependence calibration plots.}

\item{PassInGrid}{Pass in a grid for changing up the parameter settings for catboost}

\item{GridTune}{Set to TRUE if you want to grid tune the models}

\item{BaselineComparison}{= 'default',}

\item{MaxModelsInGrid}{= 1L,}

\item{MaxRunsWithoutNewWinner}{= 20L,}

\item{MaxRunMinutes}{= 60L*60L,}

\item{MetricPeriods}{= 25L,}

\item{Langevin}{TRUE or FALSE}

\item{DiffusionTemperature}{Default 10000}

\item{Trees}{Provide a named list to have different number of trees for each model. Trees = list('classifier' = seq(1000,2000,100), 'regression' = seq(1000,2000,100))}

\item{Depth}{= seq(4L, 8L, 1L),}

\item{RandomStrength}{1}

\item{BorderCount}{128}

\item{LearningRate}{= seq(0.01,0.10,0.01),}

\item{L2_Leaf_Reg}{= seq(1.0, 10.0, 1.0),}

\item{RSM}{= c(0.80, 0.85, 0.90, 0.95, 1.0),}

\item{BootStrapType}{= c('Bayesian', 'Bernoulli', 'Poisson', 'MVS', 'No'),}

\item{GrowPolicy}{= c('SymmetricTree', 'Depthwise', 'Lossguide')}

\item{Shuffles}{= 2L,}
}
\value{
Returns AutoCatBoostRegression() model objects: VariableImportance.csv, Model, ValidationData.csv, EvalutionPlot.png, EvalutionBoxPlot.png, EvaluationMetrics.csv, ParDepPlots.R a named list of features with partial dependence calibration plots, ParDepBoxPlots.R, GridCollect, and catboostgrid
}
\description{
AutoCatBoostHurdleModel for generalized hurdle modeling. Check out the Readme.Rd on github for more background.
}
\examples{
\dontrun{
# Test data.table
CatBoost_QA <- data.table::CJ(
  TOF = c(TRUE,FALSE),
  Classification = c(TRUE,FALSE),
  TaskType = c("CPU","GPU"),
  Success = "Failure",
  PartitionInFunction = c(TRUE,FALSE), sorted = FALSE
)

# Remove impossible combinations
CatBoost_QA <- CatBoost_QA[!(PartitionInFunction & TOF)]
CatBoost_QA[, RunNumber := seq_len(.N)]


# Path File
Path <- getwd()

#       TOF Classification TaskType Success PartitionInFunction RunNumber
# 1:   TRUE           TRUE      CPU Failure               FALSE         1  success
# 2:   TRUE           TRUE      GPU Failure               FALSE         2  success
# 3:   TRUE          FALSE      CPU Failure               FALSE         3  success
# 4:   TRUE          FALSE      GPU Failure               FALSE         4  success
# 5:  FALSE           TRUE      CPU Failure                TRUE         5  fail
# 6:  FALSE           TRUE      CPU Failure               FALSE         6  fail
# 7:  FALSE           TRUE      GPU Failure                TRUE         7  fail
# 8:  FALSE           TRUE      GPU Failure               FALSE         8  fail
# 9:  FALSE          FALSE      CPU Failure                TRUE         9  fail
# 10: FALSE          FALSE      CPU Failure               FALSE        10  fail
# 11: FALSE          FALSE      GPU Failure                TRUE        11  fail
# 12: FALSE          FALSE      GPU Failure               FALSE        12  fail

# AutoCatBoostHurdleModel
# run = 1
# run = 2
for(run in seq_len(CatBoost_QA[,.N])) {

  # Define values
  tasktypemode <- CatBoost_QA[run, TaskType]
  tof <- CatBoost_QA[run, TOF]
  PartitionInFunction <- CatBoost_QA[run, PartitionInFunction]
  Classify <- CatBoost_QA[run, Classification]
  Tar <- "Adrian"

  # Get data
  if(Classify) {
    data <- RemixAutoML::FakeDataGenerator(N = 15000, ZIP = 1)
  } else {
    data <- RemixAutoML::FakeDataGenerator(N = 15000, ZIP = 2)
  }

  # Partition Data
  if(!tof && !PartitionInFunction) {
    Sets <- RemixAutoML::AutoDataPartition(
      data = data,
      NumDataSets = 3,
      Ratios = c(0.7,0.2,0.1),
      PartitionType = "random",
      StratifyColumnNames = "Adrian",
      TimeColumnName = NULL)
    TTrainData <- Sets$TrainData
    VValidationData <- Sets$ValidationData
    TTestData <- Sets$TestData
    rm(Sets)
  } else {
    TTrainData <- data.table::copy(data)
    VValidationData <- NULL
    TTestData <- NULL
  }

  # Run function
  TestModel <- tryCatch({RemixAutoML::AutoCatBoostHurdleModel(

    # Operationalization
    task_type = 'GPU',
    ModelID = 'ModelTest',
    SaveModelObjects = FALSE,
    ReturnModelObjects = TRUE,

    # Data related args
    data = TTrainData,
    ValidationData = VValidationData,
    TestData = TTestData,
    WeightsColumnName = NULL,
    TrainOnFull = tof,
    Buckets = if(Classify) 0L else c(0,2,3),
    TargetColumnName = "Adrian",
    FeatureColNames = names(TTrainData)[!names(data) \%in\% c("Adrian","IDcol_1","IDcol_2","IDcol_3","IDcol_4","IDcol_5","DateTime")],
    PrimaryDateColumn = "DateTime",
    IDcols = c("IDcol_1","IDcol_2","IDcol_3","IDcol_4","IDcol_5","DateTime"),
    EncodingMethod = list('classifier' = 'credibility', 'regression' = 'credibility'),
    DebugMode = TRUE,

    # Metadata args
    Paths = Path,
    MetaDataPaths = Path,
    TransformNumericColumns = NULL,
    Methods = c('Asinh', 'Asin', 'Log', 'LogPlus1', 'Sqrt', 'Logit'),
    ClassWeights = NULL,
    SplitRatios = if(PartitionInFunction) c(0.70, 0.20, 0.10) else NULL,
    NumOfParDepPlots = 10L,

    # Grid tuning setup
    PassInGrid = NULL,
    GridTune = FALSE,
    BaselineComparison = 'default',
    MaxModelsInGrid = 1L,
    MaxRunsWithoutNewWinner = 20L,
    MaxRunMinutes = 60L*60L,
    MetricPeriods = 25L,

    # Bandit grid args
    Langevin = FALSE,
    DiffusionTemperature = 10000,
    Trees = list('classifier' = 50, 'regression' = 50),
    Depth = list('classifier' = 4, 'regression' = 4),
    RandomStrength = list('classifier' = 1, 'regression' = 1),
    BorderCount = list('classifier' = 32, 'regression' = 32),
    LearningRate = list('classifier' = 0.01, 'regression' = 0.01),
    L2_Leaf_Reg = list('classifier' = 3.0, 'regression' = 1.0),
    RSM = list('classifier' = 0.80, 'regression' = 0.80),
    BootStrapType = list('classifier' = 'Bayesian', 'regression' = 'Bayesian'),
    GrowPolicy = list('classifier' = 'SymmetricTree', 'regression' = 'SymmetricTree'))}, error = function(x) NULL)

  # Outcome
  if(!is.null(TestModel)) CatBoost_QA[run, Success := "Success"]
  TestModel <- NULL
  gc(); Sys.sleep(5)
  data.table::fwrite(CatBoost_QA, file = file.path(Path, "AutoCatBoostHurdleModel_QA.csv"))

  # Outcome
  if(!is.null(TestModel)) CatBoost_QA[run, Success := "Success"]
  data.table::fwrite(CatBoost_QA, file = file.path(Path, "AutoCatBoostHurdleModel_QA.csv"))

  # Score CatBoost Hurdle Model
  Output <- tryCatch({RemixAutoML::AutoCatBoostHurdleModelScoring(
    TestData = TTrainData,
    Path = Path,
    ModelID = "ModelTest",
    ModelList = TestModel$ModelList,
    ArgsList = TestModel$ArgsList,
    Threshold = NULL)}, error = function(x) NULL)

  # Outcome
  if(!is.null(Output)) CatBoost_QA[run, ScoreSuccess := "Success"]
  TestModel <- NULL
  Output <- NULL
  gc(); Sys.sleep(5)
  data.table::fwrite(CatBoost_QA, file = file.path(Path, "AutoCatBoostHurdleModel_QA.csv"))
}
}
}
\seealso{
Other Supervised Learning - Hurdle Modeling: 
\code{\link{AutoH2oDRFHurdleModel}()},
\code{\link{AutoH2oGBMHurdleModel}()},
\code{\link{AutoLightGBMHurdleModel}()},
\code{\link{AutoXGBoostHurdleModel}()}
}
\author{
Adrian Antico
}
\concept{Supervised Learning - Hurdle Modeling}
