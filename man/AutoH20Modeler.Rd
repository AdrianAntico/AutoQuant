% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Adrian_Antico_Modeling_Tools_Library.R
\name{AutoH20Modeler}
\alias{AutoH20Modeler}
\title{An Automated Machine Learning Framework using H20}
\usage{
AutoH20Modeler(Construct, max_memory, ratios, BL_Trees, nthreads,
  model_path, MaxRuntimeSeconds = 3600, MaxModels = 30)
}
\arguments{
\item{Construct}{Core instruction file for automation}

\item{max_memory}{The ceiling amount of memory H20 will utilize}

\item{ratios}{The percentage of train samples from source data (remainder goes to validation set)}

\item{BL_Trees}{The number of trees to build in baseline GBM or RandomForest}

\item{nthreads}{Set the number of threads to run function}

\item{model_path}{Directory path for where you want your models saved}

\item{MaxRuntimeSeconds}{Number of seconds of run time for grid tuning}

\item{MaxModels}{Number of models you'd like to have returned}

\item{Targets}{Names of target variables in source data}

\item{Distribution}{Distribution family, e.g. bernoulli}

\item{Loss}{Loss metric for model, e.g. AUC for binary classification}

\item{Quantile}{The numeric decimal representing the quantile you wish to model}

\item{ModelName}{The name for your model}

\item{Algorithm}{Name of algo, i.e. gbm, randomForest, deeplearning}

\item{dataName}{The name of the data used to build model}

\item{TargetCol}{The reference to the target variable}

\item{FeatureCols}{The reference to the feature variables}

\item{CreateDate}{Set the date of when this file was created}

\item{GridTune}{Set to TRUE / FALSE}

\item{ExportValidData}{Set to TRUE / FALSE to export the validation data with predictions}

\item{ParDep}{Set a number N to return the partial dependence plots for the top N features from variable importance}

\item{PD_Data}{Specify to use all, train, or validation data to build partial dependence plots}

\item{ThreshType}{For binary classification, choose from "f1", "f2", "f0point5", or "CS" (Cost Sensitive)}

\item{FSC}{Feature selection criteria: choose the variable importance percentage cutoff}

\item{tpProfit}{True Positive Profit amount}

\item{tnProfit}{True Negative Profit amount}

\item{fpProfit}{False Positive Profit amount}

\item{fnProfit}{False Negative Profit amount}

\item{SaveModel}{Set to TRUE to save model}

\item{SaveModelType}{Set to standard for h2o file, mojo for mojo file}

\item{PredsAllData}{Set to TRUE to export all data (train + validate) with predicted values}

\item{TargetEncoding}{Put the column numbers in a vector for those you wish to run target encoding on}
}
\value{
Returns saved models, corrected Construct file, variable importance tables, evaluation and partial dependence calibration plots, model performance measure, etc.
}
\description{
1. Logic: Error checking in the modeling arguments from your Construction file
2. ML: Build grid-tuned models and baseline models for comparison and checks which one performs better on validation data
3. Evaluation: Collects the performance metrics for both
4. Evaluation: Generates calibration plots (and boxplots for regression) for the winning model
5. Evaluation: Generates partial dependence calibration plots (and boxplots for regression) for the winning model
6. Evaluation: Generates variable importance tables and a table of non-important features
7. Production: Creates a storage file containing: model name, model path, grid tune performance, baseline performance, and threshold (if classification) and stores that file in your model_path location
}
\examples{
Correl <- 0.85
aa <- data.table(target = runif(10000))
aa[, x1 := qnorm(target)]
aa[, x2 := runif(10000)]
aa[, Independent_Variable1 := log(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
aa[, Independent_Variable2 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
aa[, Independent_Variable3 := exp(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
aa[, Independent_Variable4 := exp(exp(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2))))]
aa[, Independent_Variable5 := sqrt(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
aa[, Independent_Variable6 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.10]
aa[, Independent_Variable7 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.25]
aa[, Independent_Variable8 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.75]
aa[, Independent_Variable9 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^2]
aa[, Independent_Variable10 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^4]
aa[, ':=' (x1 = NULL, x2 = NULL)]
aa[, target := as.factor(ifelse(target > 0.5,1,0))]
N = 1
Construct <- data.table(Targets         = "target",
                       Distribution    = "bernoulli",
                       Loss            = "AUC",
                       Quantile        = 0.01,
                       ModelName       = "bla",
                       Algorithm       = "gbm",
                       dataName        = "aa",
                       TargetCol       = c("1"),
                       FeatureCols     = c("2:4"),
                       CreateDate      = Sys.time(),
                       GridTune        = FALSE,
                       ExportValidData = TRUE,
                       ParDep          = 10,
                       PD_Data         = "All",
                       ThreshType      = "f1",
                       FSC             = 0.001,
                       tpProfit        = rep(0,N),
                       tnProfit        = rep(0,N),
                       fpProfit        = rep(-1,N),
                       fnProfit        = rep(-5,N),
                       SaveModel       = rep("FALSE",N),
                       SaveModelType   = rep("Mojo",N),
                       PredsAllData    = rep(TRUE,N),
                       TargetEncoding  = rep("c(3:9)",N))
AutoH20Modeler(Construct,
              max_memory = "28G",
              ratios = 0.75,
              BL_Trees = 500,
              nthreads = 5,
              model_path = getwd())
}
\author{
Adrian Antico
}
