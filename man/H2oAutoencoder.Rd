% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/H2oAutoencoder.R
\name{H2oAutoencoder}
\alias{H2oAutoencoder}
\title{H2oAutoencoder for anomaly detection and dimensionality reduction}
\usage{
H2oAutoencoder(
  AnomalyDetection = TRUE,
  DimensionReduction = TRUE,
  data,
  ValidationData = NULL,
  Features = NULL,
  RemoveFeatures = FALSE,
  NThreads = max(1L, parallel::detectCores() - 2L),
  MaxMem = "28G",
  H2oShutdown = TRUE,
  ModelID = "TestModel",
  LayerStructure = NULL,
  ReturnLayer = 4L,
  per_feature = TRUE,
  Activation = "Tanh",
  Epochs = 5L,
  L2 = 0.1,
  ElasticAveraging = TRUE,
  ElasticAveragingMovingRate = 0.9,
  ElasticAveragingRegularization = 0.001
)
}
\arguments{
\item{AnomalyDetection}{Set to TRUE to run anomaly detection}

\item{DimensionReduction}{Set to TRUE to run dimension reduction}

\item{data}{The data.table with the columns you wish to have analyzed}

\item{ValidationData}{The data.table with the columns you wish to have scored}

\item{Features}{NULL Column numbers or column names}

\item{RemoveFeatures}{Set to TRUE if you want the features you specify in the Features argument to be removed from the data returned}

\item{NThreads}{max(1L, parallel::detectCores()-2L)}

\item{MaxMem}{"28G"}

\item{H2oShutdown}{Setting to TRUE will shutdown H2O when it done being used internally.}

\item{ModelID}{"TestModel"}

\item{LayerStructure}{a}

\item{ReturnLayer}{Which layer of the NNet to return. Choose from 1-7 with 4 being the layer with the least amount of nodes}

\item{per_feature}{Set to TRUE to have per feature anomaly detection generated. Otherwise and overall value will be generated}

\item{Activation}{Choose from "Tanh", "TanhWithDropout", "Rectifier", "RectifierWithDropout","Maxout", "MaxoutWithDropout"}

\item{Epochs}{Quantile value to find the cutoff value for classifying outliers}

\item{L2}{Specify the amount of memory to allocate to H2O. E.g. "28G"}

\item{ElasticAveraging}{Specify the number of threads (E.g. cores * 2)}

\item{ElasticAveragingMovingRate}{Specify the number of decision trees to build}

\item{ElasticAveragingRegularization}{Specify the row sample rate per tree}
}
\value{
A data.table
}
\description{
H2oAutoencoder for anomaly detection and or dimensionality reduction
}
\examples{
\dontrun{

# Create simulated data

# Define correlation strength of features to target
Correl <- 0.85

# Number of rows you want returned
N <- 10000

# Create data
data <- data.table::data.table(Adrian = runif(N))
data[, x1 := qnorm(Adrian)]
data[, x2 := runif(N)]
data[, Independent_Variable1 := log(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
data[, Independent_Variable2 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
data[, Independent_Variable3 := exp(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
data[, Independent_Variable4 := exp(exp(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2))))]
data[, Independent_Variable5 := sqrt(pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))]
data[, Independent_Variable6 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.10]
data[, Independent_Variable7 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.25]
data[, Independent_Variable8 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^0.75]
data[, Independent_Variable9 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^2]
data[, Independent_Variable10 := (pnorm(Correl * x1 + sqrt(1-Correl^2) * qnorm(x2)))^4]
data[, Independent_Variable11 := as.factor(
 data.table::fifelse(Independent_Variable2 < 0.15, "A",
        data.table::fifelse(Independent_Variable2 < 0.45, "B",
               data.table::fifelse(Independent_Variable2 < 0.65,  "C",
                      data.table::fifelse(Independent_Variable2 < 0.85,  "D", "E")))))]
data.table::set(data, j = c("x1", "x2"), value = NULL)

# Get number of columns for LayerStructure
N <- length(names(data)[2L:ncol(data)])

# Run algo
Output <- RemixAutoML::H2oAutoencoder(

   # Select the service
   AnomalyDetection = TRUE,
   DimensionReduction = TRUE,

   # Data related args
   data = data,
   ValidationData = NULL,
   Features = names(data)[2L:ncol(data)],
   RemoveFeatures = FALSE,

   # H2O args
   NThreads = max(1L, parallel::detectCores()-2L),
   MaxMem = "28G",
   H2oShutdown = TRUE,
   ModelID = "TestModel",
   LayerStructure = NULL,
   ReturnLayer = 4L,
   per_feature = TRUE,
   Activation = "Tanh",
   Epochs = 5L,
   L2 = 0.10,
   ElasticAveraging = TRUE,
   ElasticAveragingMovingRate = 0.90,
   ElasticAveragingRegularization = 0.001)

 # Inspect output
 Data <- Output$Data
 Model <- Output$Model

 # If ValidationData is not null
 ValidationData <- Output$ValidationData
}
}
\seealso{
Other Feature Engineering: 
\code{\link{AutoDataPartition}()},
\code{\link{AutoHierarchicalFourier}()},
\code{\link{AutoInteraction}()},
\code{\link{AutoLagRollStatsScoring}()},
\code{\link{AutoLagRollStats}()},
\code{\link{AutoTransformationCreate}()},
\code{\link{AutoTransformationScore}()},
\code{\link{AutoWord2VecModeler}()},
\code{\link{ContinuousTimeDataGenerator}()},
\code{\link{CreateCalendarVariables}()},
\code{\link{CreateHolidayVariables}()},
\code{\link{DT_GDL_Feature_Engineering}()},
\code{\link{DifferenceDataReverse}()},
\code{\link{DifferenceData}()},
\code{\link{DummifyDT}()},
\code{\link{ModelDataPrep}()},
\code{\link{Partial_DT_GDL_Feature_Engineering}()},
\code{\link{TimeSeriesFill}()}
}
\author{
Adrian Antico
}
\concept{Feature Engineering}
