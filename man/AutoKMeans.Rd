% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AutoKMeans.R
\name{AutoKMeans}
\alias{AutoKMeans}
\title{AutoKMeans Automated row clustering for mixed column types}
\usage{
AutoKMeans(
  data,
  nthreads = 8,
  MaxMem = "28G",
  SaveModels = NULL,
  PathFile = NULL,
  GridTuneGLRM = TRUE,
  GridTuneKMeans = TRUE,
  glrmCols = c(1:5),
  IgnoreConstCols = TRUE,
  glrmFactors = 5,
  Loss = "Absolute",
  glrmMaxIters = 1000,
  SVDMethod = "Randomized",
  MaxRunTimeSecs = 3600,
  KMeansK = 50,
  KMeansMetric = "totss"
)
}
\arguments{
\item{data}{is the source time series data.table}

\item{nthreads}{set based on number of threads your machine has available}

\item{MaxMem}{set based on the amount of memory your machine has available}

\item{SaveModels}{Set to "standard", "mojo", or NULL (default)}

\item{PathFile}{Set to folder where you will keep the models}

\item{GridTuneGLRM}{If you want to grid tune the glrm model, set to TRUE, FALSE otherwise}

\item{GridTuneKMeans}{If you want to grid tuen the KMeans model, set to TRUE, FALSE otherwise}

\item{glrmCols}{the column numbers for the glrm}

\item{IgnoreConstCols}{tell H2O to ignore any columns that have zero variance}

\item{glrmFactors}{similar to the number of factors to return from PCA}

\item{Loss}{set to one of "Quadratic", "Absolute", "Huber", "Poisson", "Hinge", "Logistic", "Periodic"}

\item{glrmMaxIters}{max number of iterations}

\item{SVDMethod}{choose from "Randomized","GramSVD","Power"}

\item{MaxRunTimeSecs}{set the timeout for max run time}

\item{KMeansK}{number of factors to test out in k-means to find the optimal number}

\item{KMeansMetric}{pick the metric to identify top model in grid tune c("totss","betweenss","withinss")}
}
\value{
Original data.table with added column with cluster number identifier
}
\description{
AutoKMeans adds a column to your original data with a cluster number identifier. Uses glrm (grid tune-able) and then k-means to find optimal k.
}
\examples{
\dontrun{
data <- data.table::as.data.table(iris)
data <- AutoKMeans(
  data,
  nthreads = 8,
  MaxMem = "28G",
  SaveModels = NULL,
  PathFile = normalizePath("./"),
  GridTuneGLRM = TRUE,
  GridTuneKMeans = TRUE,
  glrmCols = 1:(ncol(data)-1),
  IgnoreConstCols = TRUE,
  glrmFactors = 2,
  Loss = "Absolute",
  glrmMaxIters = 1000,
  SVDMethod = "Randomized",
  MaxRunTimeSecs = 3600,
  KMeansK = 5,
  KMeansMetric = "totss")
unique(data[["Species"]])
unique(data[["ClusterID"]])
temp <- data[, mean(ClusterID), by = "Species"]
Setosa <- round(temp[Species == "setosa", V1][[1]],0)
Versicolor <- round(temp[Species == "versicolor", V1][[1]],0)
Virginica <- round(temp[Species == "virginica", V1][[1]],0)
data[, Check := "a"]
data[ClusterID == eval(Setosa), Check := "setosa"]
data[ClusterID == eval(Virginica), Check := "virginica"]
data[ClusterID == eval(Versicolor), Check := "versicolor"]
data[, Acc := as.numeric(ifelse(Check == Species, 1, 0))]
data[, mean(Acc)][[1]]
}
}
\seealso{
Other Unsupervised Learning: 
\code{\link{GenTSAnomVars}()},
\code{\link{H2oIsolationForest}()},
\code{\link{ResidualOutliers}()}
}
\author{
Adrian Antico
}
\concept{Unsupervised Learning}
