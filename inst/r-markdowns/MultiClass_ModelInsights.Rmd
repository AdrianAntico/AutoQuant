---
title: "MultiClass Evaluation & Insights"
author: "Provided by AutoQuant"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  prettydoc::html_pretty:
    theme: AutoQuant
    toc: yes
    toc_depth: 2
    fig_caption: yes
    number_sections: yes
classoption: landscape
---

```{r Environment, include=FALSE}
# theme options up top: hpstr, cayman, architect, AutoQuant
knitr::opts_chunk$set(echo = TRUE)
temp <- globalenv()
TempNames <- names(temp)
for(nam in TempNames) {
  assign(x = nam, value = eval(temp[[nam]]), envir = .GlobalEnv)
}
```

```{r ModelObject_Model_MetaData, echo = FALSE}
if(!is.null(ModelObject)) {
  
  # Model MetaData ----

  ## Model_MetaData_Parameters ----
  ArgsList <- ModelObject[['ArgsList']]
  
  ## Model_MetaData_GridMetrics ----
  GridMetrics <- ModelObject[['GridMetrics']]
  
}
``` 

```{r ModelObject_DataSets_And_MetaData, echo = FALSE}
if(!is.null(ModelObject)) {
  
  # DataSets
  TestData <- ModelObject[['TestData']]
  ValidationData <- ModelObject[['ValidationData']]
  TrainData <- ModelObject[['TrainData']]
  
  # Meta info
  TargetColumnName <- ModelObject[['ArgsList']][['TargetColumnName']]
  TargetLevels <- ModelObject[['ArgsList']][['TargetLevels']]
  PredictionColumnName <- PredictionColumnName
  if(is.null(FeatureColumnNames)) {
    FeatureColumnNames <- ModelObject[['ColNames']][[1L]]
  }
  if(is.null(DateColumnName) && !is.null(ModelObject[['ArgsList']][['PrimaryDateColumn']])) {
    DateColumnName <- ModelObject[['ArgsList']][['PrimaryDateColumn']]
  } else {
    DateColumnName <- NULL
  }
}
```

```{r ModelObject_Evaluation_Metrics, echo = FALSE}
if(!is.null(ModelObject)) {
  
  # Evaluation Metrics ----
  
  ## MultiClass Metrics ----
  Test_MultiClassMetrics <- ModelObject[['MultinomialMetrics']][['TestData']]
  Train_MultiClassMetrics <- ModelObject[['MultinomialMetrics']][['TrainData']]

  # Update Colnames
  if(!is.null(Test_MultiClassMetrics)) Test_MultiClassMetrics[, Data_Source := 'Test']
  if(!is.null(Train_MultiClassMetrics)) Train_MultiClassMetrics[, Data_Source := 'Train']

  # CatBoost only
  if(is.null(Test_MultiClassMetrics) && is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- NULL
  } else if(!is.null(Test_MultiClassMetrics) && !is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- data.table::rbindlist(list(
      Test_MultiClassMetrics, Train_MultiClassMetrics))
  } else if(is.null(Test_MultiClassMetrics) && !is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- Train_MultiClassMetrics
  } else if(!is.null(Test_MultiClassMetrics) && is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- Test_MultiClassMetrics
  } else {
    All_MultiClassMetrics <- NULL
  }
  
  
  ## Model_Evaluation_Metrics ----
  EvalMetricsNames <- names(ModelObject[['EvaluationMetrics']])
  Test_EvalMetricss <- EvalMetricsNames[which(EvalMetricsNames %like% 'TestData_')]
  Test_EvalMetrics <- list()
  for(nam in Test_EvalMetricss) Test_EvalMetrics[[nam]] <- ModelObject[['EvaluationMetrics']][[nam]]
  Train_EvalMetricss <- setdiff(EvalMetricsNames, Test_EvalMetricss)
  Train_EvalMetrics <- list()
  for(nam in Train_EvalMetricss) Train_EvalMetrics[[nam]] <- ModelObject[['EvaluationMetrics']][[nam]]
  
  ## Model_VarImportanceTable ----
  if(tolower(Algo) == 'catboost') {
    Test_Importance <- ModelObject[['VariableImportance']][['Test_Importance']]
    Validation_Importance <- ModelObject[['VariableImportance']][['Validation_Importance']]
    Train_Importance <- ModelObject[['VariableImportance']][['Train_Importance']]

    # Update Colnames
    if(!is.null(Test_Importance)) data.table::setnames(Test_Importance, old = 'Importance', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Importance)) data.table::setnames(Validation_Importance, old = 'Importance', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Importance)) data.table::setnames(Train_Importance, old = 'Importance', new = 'Train_Importance', skip_absent = TRUE)

    # CatBoost only
    if(is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- NULL
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
      All_Importance <- merge(All_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Validation_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- Train_Importance
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Validation_Importance
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Test_Importance
    } else {
      All_Importance <- NULL
    }
    
  } else {
    
    #### Encoding-Based Models
    if(is.null(Test_Importance_dt)) {
      Test_Importance <- NULL
    } else {
      Test_Importance <- Test_Importance_dt
    }
    if(is.null(Validation_Importance_dt)) {
      Validation_Importance <- NULL
    } else {
      Validation_Importance <- Validation_Importance_dt
    }
    if(is.null(Train_Importance_dt)) {
      Train_Importance <- ModelObject[['VariableImportance']]
    } else {
      Train_Importance <- Train_Importance_dt
    }
    
    # Update Colnames
    if(!is.null(Test_Importance)) data.table::setnames(Test_Importance, old = 'Importance', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Importance)) data.table::setnames(Validation_Importance, old = 'Importance', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Importance)) data.table::setnames(Train_Importance, old = 'Importance', new = 'Train_Importance', skip_absent = TRUE)

    # CatBoost only
    if(is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- NULL
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
      All_Importance <- merge(All_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Validation_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- Train_Importance
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Validation_Importance
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Test_Importance
    } else {
      All_Importance <- NULL
    }
  }
  
  ## Model_IntImportanceTable ----
  if(tolower(Algo) == 'catboost') {
    Test_Interaction <- ModelObject[['InteractionImportance']][['Test_Interaction']]
    Validation_Interaction <- ModelObject[['InteractionImportance']][['Validation_Interaction']]
    Train_Interaction <- ModelObject[['InteractionImportance']][['Train_Interaction']]
    
    # Update Colnames
    if(!is.null(Test_Interaction)) data.table::setnames(Test_Interaction, old = 'score', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Interaction)) data.table::setnames(Validation_Interaction, old = 'score', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Interaction)) data.table::setnames(Train_Interaction, old = 'score', new = 'Train_Importance', skip_absent = TRUE)

    # CatBoost only
    if(is.null(Test_Interaction) && is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- NULL
    } else if(!is.null(Test_Interaction) && !is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Validation_Interaction, by = c('Features1','Features2'), all = TRUE)
      All_Interaction <- merge(All_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(!is.null(Test_Interaction) && !is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Validation_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(!is.null(Test_Interaction) && is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(is.null(Test_Interaction) && !is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Validation_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(is.null(Test_Interaction) && is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- Train_Interaction
    } else if(is.null(Test_Interaction) && !is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- Validation_Interaction
    } else if(!is.null(Test_Interaction) && is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- Test_Interaction
    } else {
      All_Interaction <- NULL
    }
  }
}
``` 

```{r Generic_DataSets_And_MetaData, echo = FALSE}
if(is.null(ModelObject)) {
  
  # DataSets
  if(is.null(TestData) && file.exists(file.path(SourcePath, paste0(ModelID, "_ValidationData.csv")))) {
    TestData <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_ValidationData.csv")))
  }
  # Validate
  if(is.null(ValidationData) && file.exists(file.path(SourcePath, paste0(ModelID, "_ValData.csv")))) {
    ValidationDataData <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_ValData.csv")))
  }
  # Train
  if(is.null(TrainData) && file.exists(file.path(SourcePath, paste0(ModelID, "_TrainData.csv")))) {
    TrainData <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_TrainData.csv")))
  }
  
  # Meta info
  TargetColumnName <- TargetColumnName
  PredictionColumnName <- PredictionColumnName
  if(is.null(FeatureColumnNames) && !is.null(TestData)) {
    FeatureColumnNames <- names(TestData)[!names(TestData) %in% c(TargetColumnName, PredictionColumnName)]
  }
  if(is.null(FeatureColumnNames) && !is.null(ValidationData)) {
    FeatureColumnNames <- names(ValidationData)[!names(ValidationData) %in% c(TargetColumnName, PredictionColumnName)]
  }
  if(is.null(FeatureColumnNames) && !is.null(TrainData)) {
    FeatureColumnNames <- names(TrainData)[!names(TrainData) %in% c(TargetColumnName, PredictionColumnName)]
  }
  if(is.list(FeatureColumnNames) || data.table::is.data.table(FeatureColumnNames)) {
    FeatureColumnNames <- FeatureColumnNames[[1L]]
  }
  if(is.null(DateColumnName) && !is.null(ModelObject[['ArgsList']][['PrimaryDateColumn']])) {
    DateColumnName <- ModelObject[['ArgsList']][['PrimaryDateColumn']]
  } else {
    DateColumnName <- NULL
  }
  
  # Target levels
  counter <- 1L
  DataList <- list()
  DataList[['TrainData']] <- TrainData
  DataList[['ValidationData']] <- ValidationData
  DataList[['TestData']] <- TestData
  for(d in names(DataList)) {
    DataList[[d]] <- DataList[[d]][, .N, by = c(eval(TargetColumnName))]
  }
  
  # Keep for functions that need the table
  TargetLevels.. <- data.table::rbindlist(DataList)
  data.table::setnames(TargetLevels.., TargetColumnName, 'OriginalLevels')
  TargetLevels.. <- TargetLevels..[, list(N = sum(N)), by = 'OriginalLevels']
  TargetLevels <- sort(TargetLevels..[, unique(OriginalLevels)])
  rm(DataList)
}
```

```{r Generic_Model_MetaData, echo = FALSE}
if(is.null(ModelObject)) {

  # Model MetaData ----

  ## Model_MetaData_Parameters ----
  if(!is.null(SourcePath) && !is.null(ModelID)) {
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_ArgsList.Rdata")))) {
      load(file.path(SourcePath, paste0(ModelID, "_ArgsList.Rdata")))
    }
  } else {
    ArgsList <- NULL
  }

  ## Model_MetaData_GridMetrics ----
  if(!is.null(SourcePath) && !is.null(ModelID)) {
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_GridMetrics.csv")))) {
      GridMetrics <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_GridMetrics.csv")))
    } else {
      GridMetrics <- NULL
    }
  } else {
    GridMetrics <- NULL
  }
}
```
  
```{r Generic_Evaluation_Metrics, echo = FALSE}
if(is.null(ModelObject)) {
  
  # Evaluation Metrics ----
  
  ## MultiClass Metrics ----
  Test_MultiClassMetrics <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Test_EvaluationMetrics.csv")))
  Train_MultiClassMetrics <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Train_EvaluationMetrics.csv")))

  # Update Colnames
  if(!is.null(Test_MultiClassMetrics)) Test_MultiClassMetrics[, Data_Source := 'Test']
  if(!is.null(Train_MultiClassMetrics)) Train_MultiClassMetrics[, Data_Source := 'Train']

  # CatBoost only
  if(is.null(Test_MultiClassMetrics) && is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- NULL
  } else if(!is.null(Test_MultiClassMetrics) && !is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- data.table::rbindlist(list(
      Test_MultiClassMetrics, Train_MultiClassMetrics))
  } else if(is.null(Test_MultiClassMetrics) && !is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- Train_MultiClassMetrics
  } else if(!is.null(Test_MultiClassMetrics) && is.null(Train_MultiClassMetrics)) {
    All_MultiClassMetrics <- Test_MultiClassMetrics
  } else {
    All_MultiClassMetrics <- NULL
  }
  
    
  ## Model_Evaluation_Metrics ----
  
  ### Test
  if(!is.null(TestData) && !file.exists(file.path(SourcePath, paste0(ModelID, "_Test_EvaluationMetrics.csv")))) {
    Test_EvalMetrics <- AutoQuant:::MultiClassMetrics(
      ModelClass='catboost',
      DataType = 'Test',
      SaveModelObjects.=FALSE,
      ValidationData.=TestData,
      PredictData.=NULL,
      TrainOnFull.=FALSE,
      TargetColumnName.=TargetColumnName,
      TargetLevels.=TargetLevels..,
      ModelID.=ModelID,
      model_path.=NULL,
      metadata_path.=NULL)
  } else if(file.exists(file.path(SourcePath, paste0(ModelID, "_Test_EvaluationMetrics.csv")))) {
    Test_EvalMetrics <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Test_EvaluationMetrics.csv")))
  } else {
    Test_EvalMetrics <- NULL
  }

  ### Train
  if(!is.null(TrainData) && !file.exists(file.path(SourcePath, paste0(ModelID, "_Train_EvaluationMetrics.csv")))) {
    Train_EvalMetrics <- AutoQuant:::MultiClassMetrics(
      ModelClass='catboost',
      DataType = 'Test',
      SaveModelObjects.=FALSE,
      ValidationData.=TrainData,
      PredictData.=NULL,
      TrainOnFull.=FALSE,
      TargetColumnName.=TargetColumnName,
      TargetLevels.=TargetLevels..,
      ModelID.=ModelID,
      model_path.=NULL,
      metadata_path.=NULL)
  } else if(file.exists(file.path(SourcePath, paste0(ModelID, "_Train_EvaluationMetrics.csv")))) {
    Train_EvalMetrics <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Train_EvaluationMetrics.csv")))
  } else {
    Train_EvalMetrics <- NULL
  }
  
  ## Model_VarImportanceTable ----
  if(tolower(Algo) == 'catboost') {
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Test_Importance_VariableImportance.csv")))) {
      Test_Importance <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Test_Importance_VariableImportance.csv")))
    } else {
      Test_Importance <- NULL
    }
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Validation_Importance_VariableImportance.csv")))) {
      Validation_Importance <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Validation_Importance_VariableImportance.csv")))
    } else {
      Validation_Importance <- NULL
    }
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Train_Importance_VariableImportance.csv")))) {
      Train_Importance <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Train_Importance_VariableImportance.csv")))
    } else {
      Train_Importance <- NULL
    }
    
    # Update Colnames
    if(!is.null(Test_Importance)) data.table::setnames(Test_Importance, old = 'Importance', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Importance)) data.table::setnames(Validation_Importance, old = 'Importance', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Importance)) data.table::setnames(Train_Importance, old = 'Importance', new = 'Train_Importance', skip_absent = TRUE)

    # CatBoost only
    if(is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- NULL
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
      All_Importance <- merge(All_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Validation_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- Train_Importance
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Validation_Importance
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Test_Importance
    } else {
      All_Importance <- NULL
    }
    
  } else {
    
    # Encoding-based Models + Generic Connector
    if(is.null(Test_Importance_dt)) {
      Test_Importance <- NULL
    } else {
      Test_Importance <- Test_Importance_dt
    }
    if(is.null(Validation_Importance_dt)) {
      Validation_Importance <- NULL
    } else {
      Validation_Importance <- Validation_Importance_dt
    }
    if(is.null(Train_Importance_dt)) {
      Train_Importance <- NULL
    } else {
      Train_Importance <- Train_Importance_dt
    }
    
    # Update Colnames
    if(!is.null(Test_Importance)) data.table::setnames(Test_Importance, old = 'Importance', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Importance)) data.table::setnames(Validation_Importance, old = 'Importance', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Importance)) data.table::setnames(Train_Importance, old = 'Importance', new = 'Train_Importance', skip_absent = TRUE)

    # CatBoost only
    if(is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- NULL
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
      All_Importance <- merge(All_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Validation_Importance, by = 'Variable', all = TRUE)
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Test_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- merge(Validation_Importance, Train_Importance, by = 'Variable', all = TRUE)
    } else if(is.null(Test_Importance) && is.null(Validation_Importance) && !is.null(Train_Importance)) {
      All_Importance <- Train_Importance
    } else if(is.null(Test_Importance) && !is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Validation_Importance
    } else if(!is.null(Test_Importance) && is.null(Validation_Importance) && is.null(Train_Importance)) {
      All_Importance <- Test_Importance
    } else {
      All_Importance <- NULL
    }
    
  }
  
  ## Model_IntImportanceTable ----
  if(tolower(Algo) == 'catboost') {
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Test_Interaction_Interaction.csv")))) {
      Test_Interaction <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Test_Interaction_Interaction.csv")))
    } else {
      Test_Interaction <- NULL
    }
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Validation_Interaction_Interaction.csv")))) {
      Validation_Interaction <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Validation_Interaction_Interaction.csv")))
    } else {
      Validation_Interaction <- NULL
    }
    if(file.exists(file.path(SourcePath, paste0(ModelID, "_Train_Interaction_Interaction.csv")))) {
      Train_Interaction <- data.table::fread(file = file.path(SourcePath, paste0(ModelID, "_Train_Interaction_Interaction.csv")))
    } else {
      Train_Interaction <- NULL
    }
    
    # Update Colnames
    if(!is.null(Test_Interaction)) data.table::setnames(Test_Interaction, old = 'score', new = 'Test_Importance', skip_absent = TRUE)
    if(!is.null(Validation_Interaction)) data.table::setnames(Validation_Interaction, old = 'score', new = 'Validation_Importance', skip_absent = TRUE)
    if(!is.null(Train_Interaction)) data.table::setnames(Train_Interaction, old = 'score', new = 'Train_Importance', skip_absent = TRUE)
    
    # CatBoost only
    if(is.null(Test_Interaction) && is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- NULL
    } else if(!is.null(Test_Interaction) && !is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Validation_Interaction, by = c('Features1','Features2'), all = TRUE)
      All_Interaction <- merge(All_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(!is.null(Test_Interaction) && !is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Validation_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(!is.null(Test_Interaction) && is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Test_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(is.null(Test_Interaction) && !is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- merge(Validation_Interaction, Train_Interaction, by = c('Features1','Features2'), all = TRUE)
      data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1)
    } else if(is.null(Test_Interaction) && is.null(Validation_Interaction) && !is.null(Train_Interaction)) {
      All_Interaction <- Train_Interaction
    } else if(is.null(Test_Interaction) && !is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- Validation_Interaction
    } else if(!is.null(Test_Interaction) && is.null(Validation_Interaction) && is.null(Train_Interaction)) {
      All_Interaction <- Test_Interaction
    } else {
      All_Interaction <- NULL
    }
  }
}
```

```{r Generic_Evaluation_Plots, echo = FALSE}

options(warn = -1)

# Evaluation Plots ----

## EvaluationPlots_CalibrationPlot ----

### Test ----
if(!is.null(TestData)) {
  Test_EvaluationPlot <- AutoPlots::Plot.Calibration.Line(
    dt = TestData,
    AggMethod = "mean",
    XVar = "Predict",
    YVar = TargetColumnName,
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    NumberBins = 21,
    Height = NULL,
    Width = NULL,
    Title = "Calibration Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)

} else {
  Test_EvaluationPlot <- NULL
}

### Train ----
if(!is.null(TrainData)) {
  Train_EvaluationPlot <- AutoPlots::Plot.Calibration.Line(
    dt = TrainData,
    AggMethod = "mean",
    XVar = "Predict",
    YVar = TargetColumnName,
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    NumberBins = 21,
    Height = NULL,
    Width = NULL,
    Title = "Calibration Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)

} else {
  Train_EvaluationPlot <- NULL
}

## EvaluationPlots_ROC_Plot ----

### TestData ----
if(!is.null(TestData)) {
  Test_ROCPlot <- AutoPlots::Plot.ROC(
    dt = TestData,
    SampleSize = 10000,
    XVar = "Predict",
    YVar = TargetColumnName,
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    AggMethod = "mean",
    Height = NULL,
    Width = NULL,
    Title = "Calibration Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)
  
} else {
  Test_ROCPlot <- NULL
}

### TrainData ----
if(!is.null(TrainData)) {
  Train_ROCPlot <- AutoPlots::Plot.ROC(
    dt = TrainData,
    SampleSize = 10000,
    XVar = "Predict",
    YVar = TargetColumnName,
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    AggMethod = "mean",
    Height = NULL,
    Width = NULL,
    Title = "Calibration Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)
}

## EvaluationPlots_GainsPlots ----

## Test_CumGainsChart ----
if(!is.null(TestData)) {
  Test_CumGainsChart <- AutoPlots::Plot.Gains(
    dt = TestData,
    PreAgg = FALSE,
    XVar = "Predict",
    YVar = TargetColumnName,
    ZVar = "N",
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    ZVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    NumberBins = 20,
    Height = NULL,
    Width = NULL,
    Title = "Gains Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = TRUE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)
  
} else {
  Test_CumGainsChart <- NULL
}

## Train_CumGainsChart ----
if(!is.null(TrainData)) {
  Train_CumGainsChart <- AutoPlots::Plot.Gains(
    dt = TrainData,
    PreAgg = FALSE,
    XVar = "Predict",
    YVar = TargetColumnName,
    ZVar = "N",
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    ZVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    NumberBins = 20,
    Height = NULL,
    Width = NULL,
    Title = "Gains Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = TRUE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    Debug = FALSE)
} else {
  Train_CumGainsChart <- NULL
}
```

```{r ModelObject_Model_Interpretation, echo = FALSE}

# Model Interpretation ----

## Model_Evaluation_Metrics_NumericVariables ----

### TestData ----

# Plots to Add and Remove

# Extra list mgt + par dep plot for multinomial

# Numeric-Test: Starting batch of plots
  
# Name to keep and remove
Test_ParDepPlots <- list()

# Add Plots to List per User Request
if(!is.null(TestData) && !is.null(FeatureColumnNames)) {
  for(g in FeatureColumnNames) {
    if(is.numeric(TestData[[g]])) {
      
      Test_ParDepPlots[[g]] <- AutoPlots::Plot.PartialDependence.Line(
        dt = TestData,
        XVar = g,
        YVar = TargetColumnName,
        ZVar = 'Predict',
        YVarTrans = "Identity",
        XVarTrans = "Identity",
        ZVarTrans = "Identity",
        FacetRows = 1,
        FacetCols = 1,
        FacetLevels = NULL,
        GroupVar = NULL,
        NumberBins = 20,
        AggMethod = "mean",
        Height = "600px",
        Width = "1100px",
        Title = "Partial Dependence Line",
        ShowLabels = FALSE,
        Title.YAxis = NULL,
        Title.XAxis = NULL,
        Engine = "Echarts",
        EchartsTheme = "dark",
        EchartsLabels = FALSE,
        TimeLine = TRUE,
        X_Scroll = TRUE,
        Y_Scroll = TRUE,
        BackGroundColor = "#6a6969",
        ChartColor = "#001534",
        FillColor = "#0066ff",
        FillColorReverse = "#97ff00",
        GridColor = "white",
        TextColor = "white",
        ZeroLineColor = "#ffff",
        ZeroLineWidth = 1.25,
        Debug = FALSE)
    }
  }
}


### TrainData ----

# Plots to Add and Remove

# Extra list mgt + par dep plot for multinomial

# Numeric-Train: Starting batch of plots
Train_ParDepPlots <- list()

# Add Plots to List per User Request
if(!is.null(TrainData) && !is.null(FeatureColumnNames)) {
  for(g in FeatureColumnNames) {
    if(is.numeric(TestData[[g]])) {
      
      Train_ParDepPlots[[g]] <- AutoPlots::Plot.PartialDependence.Line(
        dt = TrainData,
        XVar = g,
        YVar = TargetColumnName,
        ZVar = 'Predict',
        YVarTrans = "Identity",
        XVarTrans = "Identity",
        ZVarTrans = "Identity",
        FacetRows = 1,
        FacetCols = 1,
        FacetLevels = NULL,
        GroupVar = NULL,
        NumberBins = 20,
        AggMethod = "mean",
        Height = "600px",
        Width = "1100px",
        Title = "Partial Dependence Line",
        ShowLabels = FALSE,
        Title.YAxis = NULL,
        Title.XAxis = NULL,
        Engine = "Echarts",
        EchartsTheme = "dark",
        EchartsLabels = FALSE,
        TimeLine = TRUE,
        X_Scroll = TRUE,
        Y_Scroll = TRUE,
        BackGroundColor = "#6a6969",
        ChartColor = "#001534",
        FillColor = "#0066ff",
        FillColorReverse = "#97ff00",
        GridColor = "white",
        TextColor = "white",
        ZeroLineColor = "#ffff",
        ZeroLineWidth = 1.25,
        Debug = FALSE)
    }
  }
}
  
## Model_Evaluation_Metrics_CategoricalVariables ---- 

### Test Data ----

# Starting batch of plots
Test_ParDepCatPlots <- list()
  
# Add Plots
if(!is.null(TestData) && !is.null(FeatureColumnNames)) {
  for(g in FeatureColumnNames) {
    if(!is.numeric(TestData[[g]])) {
      
      Test_ParDepCatPlots[[g]] <- AutoPlots::Plot.PartialDependence.HeatMap(
        dt = TestData,
        XVar = g,
        YVar = TargetColumnName,
        ZVar = 'Predict',
        YVarTrans = "Identity",
        XVarTrans = "Identity",
        ZVarTrans = "Identity",
        FacetRows = 1,
        FacetCols = 1,
        FacetLevels = NULL,
        GroupVar = NULL,
        NumberBins = 20,
        AggMethod = "mean",
        Height = "600px",
        Width = "1100px",
        Title = "Partial Dependence Line",
        ShowLabels = FALSE,
        Title.YAxis = NULL,
        Title.XAxis = NULL,
        Engine = "Echarts",
        EchartsTheme = "dark",
        EchartsLabels = FALSE,
        TimeLine = TRUE,
        X_Scroll = TRUE,
        Y_Scroll = TRUE,
        BackGroundColor = "#6a6969",
        ChartColor = "#001534",
        FillColor = "#0066ff",
        FillColorReverse = "#97ff00",
        GridColor = "white",
        TextColor = "white",
        ZeroLineColor = "#ffff",
        ZeroLineWidth = 1.25,
        Debug = FALSE)
    }
  }
}
  
### Train Data ----

# Starting batch of plots
Train_ParDepCatPlots <- list()

# Add Plots
if(!is.null(TrainData) && !is.null(FeatureColumnNames)) {
  for(g in FeatureColumnNames) {
    if(!is.numeric(TrainData[[g]])) {
      
      Train_ParDepCatPlots[[g]] <- AutoPlots::Plot.PartialDependence.HeatMap(
        dt = TrainData,
        XVar = g,
        YVar = TargetColumnName,
        ZVar = 'Predict',
        YVarTrans = "Identity",
        XVarTrans = "Identity",
        ZVarTrans = "Identity",
        FacetRows = 1,
        FacetCols = 1,
        FacetLevels = NULL,
        GroupVar = NULL,
        NumberBins = 20,
        AggMethod = "mean",
        Height = "600px",
        Width = "1100px",
        Title = "Partial Dependence Line",
        ShowLabels = FALSE,
        Title.YAxis = NULL,
        Title.XAxis = NULL,
        Engine = "Echarts",
        EchartsTheme = "dark",
        EchartsLabels = FALSE,
        TimeLine = TRUE,
        X_Scroll = TRUE,
        Y_Scroll = TRUE,
        BackGroundColor = "#6a6969",
        ChartColor = "#001534",
        FillColor = "#0066ff",
        FillColorReverse = "#97ff00",
        GridColor = "white",
        TextColor = "white",
        ZeroLineColor = "#ffff",
        ZeroLineWidth = 1.25,
        Debug = FALSE)
    }
  }
}

```

Model Evaluation and Insights:

- Provide a wide range of output to investigate high level performance and insights

- Deliver high quality report design layout to reduce time to delivery of info

This report is for investigating model performance from a variety of perspectives. Each section has its own content that can be viewed if expanded. Output exists for both TestData (out of sample) and TrainData (some cases can have ValidationData results as well) for comparison purposes.

# <font size="6">Evaluation Metrics</font>
<p>

<details><summary>Expand to view content</summary>
<p>



##  <font size="5">MultiClass Metrics Tables</font>

<details><summary>MultiClass Metrics</summary>
<p>

```{r Model_MultiClass_Metrics, echo=FALSE}
if(!is.null(All_MultiClassMetrics)) {
  All_MultiClassMetrics <- All_MultiClassMetrics[Data_Source != 'Train']
  data.table::setcolorder(All_MultiClassMetrics, c(3L, 1L, 2L))
  print(knitr::kable(All_MultiClassMetrics))
} else {
  print('All_MultiClassMetrics is NULL')
}
```

</details>
</p>




##  <font size="5">Binary Metrics 1 vs All Tables</font>

<details><summary>Model Metrics Tables</summary>
<p>


### **TestData**
<p>

<details><summary>Performance Metrics</summary>
<p>

```{r Model_Evaluation_Metrics, echo=FALSE}
if(!is.null(Test_EvalMetrics)) {
  for(nam in names(Test_EvalMetrics)) {
    print(nam)
    print(knitr::kable(Test_EvalMetrics[[nam]]))
  }
} else {
  print('Test_EvalMetrics is NULL')
}
```

</details>
</p>


### **TrainData + ValidationData**
<p>

<details><summary>Performance Metrics</summary>
<p>

```{r Model_Evaluation_Metrics_Train, echo=FALSE}
if(!is.null(Train_EvalMetrics)) {
  for(nam in names(Train_EvalMetrics)) {
    print(nam)
    print(knitr::kable(Train_EvalMetrics[[nam]]))
  }
} else {
  print('Train_EvalMetrics is NULL')
}
```

</details>
</p>






##  <font size="5">Variable Importance Table</font>

<details><summary>Variable Importance</summary>
<p>

```{r Model_VarImportanceTable, echo=FALSE}
if(!is.null(All_Importance)) {
  data.table::setorderv(x = All_Importance, cols = names(All_Importance)[2L], order = -1L, na.last = TRUE)
  print(knitr::kable(All_Importance))
} else {
  print("No Importance data was provided")
}
```

</details>
</p>


##  <font size="5">Interaction Importance Table</font>
<p>

<details><summary>Interaction Importance</summary>
<p>

```{r Model_IntImportanceTable, echo=FALSE}
if(exists("All_Interaction") && !is.null(All_Interaction)) {
  data.table::setorderv(x = All_Interaction, cols = names(All_Interaction)[3L], order = -1L, na.last = TRUE)
  print(knitr::kable(All_Interaction))
} else {
  print('No interaction importance data was provided')
}
```

</details>
</p>



</details>
</p>







# <font size="6">Evaluation Plots</font>
<p>

<details><summary>Expand to view content</summary>
<p>



## <font size="5">Variable Importance Plots</font>
<p>

<details><summary>Expand to view content</summary>
<p>

```{r EvaluationPlots_VIPlot, echo=FALSE}
print('Test Data Variable Importance')
if(!is.null(Test_Importance)) {
  if("Train_Importance" %in% names(Test_Importance)) data.table::setnames(Test_Importance, 'Train_Importance', 'Importance', skip_absent = TRUE)
  if("Test_Importance" %in% names(Test_Importance)) data.table::setnames(Test_Importance, "Test_Importance", "Importance", skip_absent = TRUE)
  AutoPlots::Plot.VariableImportance(
    dt = Test_Importance,
    XVar = "Importance",
    YVar = "Variable",
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    AggMethod = "mean",
    Height = "600px",
    Width = "1100px",
    Title = "Variable Importance Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    title.fontSize = 22,
    title.fontWeight = "bold",
    title.textShadowColor = "#63aeff",
    title.textShadowBlur = 3,
    title.textShadowOffsetY = 1,
    title.textShadowOffsetX = -1,
    xaxis.fontSize = 14,
    yaxis.fontSize = 14,
    Debug = FALSE)
} else {
  print("Test_Importance is NULL")
}
print('Validation Data Variable Importance')
if(!is.null(Validation_Importance)) {
  if("Validation_Importance" %in% names(Validation_Importance)) data.table::setnames(Validation_Importance, 'Validation_Importance', 'Importance', skip_absent = TRUE)
  if("Test_Importance" %in% names(Validation_Importance)) data.table::setnames(Validation_Importance, "Test_Importance", "Importance", skip_absent = TRUE)
  AutoPlots::Plot.VariableImportance(
    dt = Validation_Importance,
    XVar = "Importance",
    YVar = "Variable",
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    AggMethod = "mean",
    Height = "600px",
    Width = "1100px",
    Title = "Variable Importance Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    title.fontSize = 22,
    title.fontWeight = "bold",
    title.textShadowColor = "#63aeff",
    title.textShadowBlur = 3,
    title.textShadowOffsetY = 1,
    title.textShadowOffsetX = -1,
    xaxis.fontSize = 14,
    yaxis.fontSize = 14,
    Debug = FALSE)
} else {
  print("Validation_Importance is NULL")
}
print('Train Data Variable Importance')
if(!is.null(Train_Importance)) {
  if("Train_Importance" %in% names(Train_Importance)) data.table::setnames(Train_Importance, 'Train_Importance', 'Importance', skip_absent = TRUE)
  if("Test_Importance" %in% names(Train_Importance)) data.table::setnames(Train_Importance, "Test_Importance", "Importance", skip_absent = TRUE)
  AutoPlots::Plot.VariableImportance(
    dt = Train_Importance,
    XVar = "Importance",
    YVar = "Variable",
    GroupVar = NULL,
    YVarTrans = "Identity",
    XVarTrans = "Identity",
    FacetRows = 1,
    FacetCols = 1,
    FacetLevels = NULL,
    AggMethod = "mean",
    Height = "600px",
    Width = "1100px",
    Title = "Variable Importance Plot",
    ShowLabels = FALSE,
    Title.YAxis = NULL,
    Title.XAxis = NULL,
    Engine = "Echarts",
    EchartsTheme = "dark",
    TimeLine = FALSE,
    X_Scroll = TRUE,
    Y_Scroll = TRUE,
    BackGroundColor = "#6a6969",
    ChartColor = "#001534",
    FillColor = "#0066ff",
    FillColorReverse = "#97ff00",
    GridColor = "white",
    TextColor = "white",
    ZeroLineColor = "#ffff",
    ZeroLineWidth = 1.25,
    title.fontSize = 22,
    title.fontWeight = "bold",
    title.textShadowColor = "#63aeff",
    title.textShadowBlur = 3,
    title.textShadowOffsetY = 1,
    title.textShadowOffsetX = -1,
    xaxis.fontSize = 14,
    yaxis.fontSize = 14,
    Debug = FALSE)
  
} else {
  print("Train_Importance is NULL")
}
```

</details>
</p>


## <font size="5">Calibration Plots</font>
<p>

<details><summary>Expand to view content</summary>
<p>

### **TestData**
<p>

<details><summary>Calibration Plot</summary>
<p>

```{r EvaluationPlots_CalibrationPlot, echo=FALSE}
if(!is.null(Test_EvaluationPlot)) {
  eval(Test_EvaluationPlot)
} else {
  print('Test_EvaluationPlot is NULL or TestData is NULL')
}
```

</details>
</p>

### **TrainData** + **ValidationData**
<p>

<details><summary>Calibration Plot</summary>
<p>

```{r EvaluationPlots_CalibrationPlot_Train, echo=FALSE}
if(!is.null(Train_EvaluationPlot)) {
  eval(Train_EvaluationPlot)
} else {
  print('Test_EvaluationPlots is NULL or TrainData is NULL')
}
```

</details>
</p>




## <font size="5">ROC Plots</font>
<p>

<details><summary>Expand to view content</summary>
<p>

### **TestData**
<p>

<details><summary>ROC Plots</summary>
<p>

```{r ROC_Plot, echo=FALSE}
if(!is.null(Test_ROCPlot)) {
  eval(Test_ROCPlot)
} else {
  print('Test_ROCPlot is NULL or TestData is NULL')
}
```

</details>
</p>

### **TrainData** + **ValidationData**
<p>

<details><summary>Expand to view content</summary>
<p>

```{r ROC_Plot_Train, echo=FALSE}
if(!is.null(Train_EvaluationPlot)) {
  eval(Train_ROCPlot)
} else {
  print('Train_ROCPlot is NULL or TrainData is NULL')
}
```

</details>
</p>




## <font size="5">Lift & Gains Plots</font>
<p>

<details><summary>Expand to view content</summary>
<p>

### **TestData**
<p>

<details><summary>Lift & Gains Plots</summary>
<p>

```{r Lift and Gains, echo=FALSE}
if(!is.null(Test_CumGainsChart)) {
  eval(Test_CumGainsChart)
} else {
  print('Test_CumGainsChart is NULL or TestData is NULL')
}
```

</details>
</p>

### **TrainData** + **ValidationData**
<p>

<details><summary>Expand to view content</summary>
<p>

```{r Lift and Gains_Train, echo=FALSE}
if(!is.null(Test_CumGainsChart)) {
  eval(Train_CumGainsChart)
} else {
  print('Train_CumGainsChart is NULL or TestData is NULL')
}
```

</details>
</p>






# <font size="6">Model Interpretation</font>
<p>

<details><summary>Expand to view content</summary>
<p>



## <font size="5">Partial Dependence Plots: Numeric-Features</font> 
<p>

<details><summary>Expand to view content</summary>
<p>


### Partial Dependence Line Plots
<p>

<details><summary>Expand to view content</summary>
<p>


#### **TestData**
<p>

<details><summary>Partital Dependence Line Plots</summary>
<p>

```{r Model_Evaluation_Metrics_NumericVariables, echo=FALSE}
options(warn = -1)
if(!is.null(Test_ParDepPlots) && length(Test_ParDepPlots) > 0) {
  echarts4r::e_arrange(Test_ParDepPlots)
} else {
  print('Test_ParDepPlots is NULL and TestData is NULL')
}
options(warn = 1)
```

</details>
</p>


#### **TrainData** + **ValidationData**
<p>

<details><summary>Partital Dependence Line Plots</summary>
<p>

```{r Model_Evaluation_Metrics_NumericVariables_Train, echo=FALSE}
options(warn = -1)
if(!is.null(Train_ParDepPlots) && length(Train_ParDepPlots) > 0) {
  echarts4r::e_arrange(Train_ParDepPlots)
} else {
  print('Train_ParDepPlots is NULL and TrainData is NULL')
}
options(warn = 1)
```

</details>
</p>



## <font size="5">Partial Partial Dependence Plots: Categorical-Features</font>
<p>

<details><summary>Expand to view content</summary>
<p>


### **TestData**
<p>

<details><summary>Partital Dependence Bar Plots</summary>
<p>

```{r Model_Evaluation_Metrics_CategoricalVariables, echo=FALSE}
options(warn = -1)
if(!is.null(Test_ParDepCatPlots) && length(Test_ParDepCatPlots) > 0) {
  echarts4r::e_arrange(Test_ParDepCatPlots)
} else {
  print('Test_ParDepCatPlots is NULL and TestData is NULL')
}
options(warn = 1)
```

</details>
</p>


### **TrainData** + **ValidationData**
<p>

<details><summary>Partital Dependence Bar Plots</summary>
<p>

```{r Model_Evaluation_Metrics_CategoricalVariables_Train, echo=FALSE}
options(warn = -1)
if(!is.null(Train_ParDepCatPlots) && length(Train_ParDepCatPlots) > 0) {
  echarts4r::e_arrange(Train_ParDepCatPlots)
} else {
  print('Train_ParDepCatPlots is NULL and TrainData is NULL')
}
options(warn = 1)
```

</details>
</p>


</details>
</p>



</details>
</p>






# <font size="6">Model MetaData</font>
<p>

<details><summary>Expand to view content</summary>
<p>


## <font size="5">Parameters and Settings</font> 

<details><summary>Model Parameters</summary>
<p>

```{r Model_MetaData_Parameters, echo=FALSE}
if(!is.null(ArgsList)) {
  for(nam in names(ArgsList)) print(paste0(nam, ": ", ArgsList[[nam]]))
} else {
  txt <- paste0(ModelID, "_ArgsList.Rdata")
  print(paste0('ArgsList is NULL'))
}
```



## <font size="5">Grid Tuning Metrics</font>

<details><summary>Grid Tuning Metrics</summary>
<p>

```{r Model_MetaData_GridMetrics, echo=FALSE}
if(!is.null(GridMetrics)) {
  print(knitr::kable(GridMetrics[order(-MetricValue)]))
} else {
  print("GridTuning was not conducted")
}
```

</details>
</p>



</details>
</p>

